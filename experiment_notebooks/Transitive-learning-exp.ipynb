{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfTOLIT50Vr0"
      },
      "source": [
        "# Transitive learning experiments\n",
        "\n",
        "This notebook reproduces the transitive learning experiments, with results\n",
        "corresponding to Figure 2B of our [paper](https://www.science.org/doi/epdf/10.1126/sciadv.adm8470).\n",
        "\n",
        "To run this notebook, you must first download the random walks dataset.  \n",
        "Instructions are available on the main [project page](https://github.com/google-deepmind/space_is_a_latent_sequence).   \n",
        "\n",
        "Ensure the correct path to the dataset is specified in the `Load data and inspect ground truth positions` section below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y83SbuERwbsA"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1HxJb8v3mYn"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from cscg import cscg_factory\n",
        "from cscg import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNpxARefwr-n"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "def extract_data_from_episode(episode_data, T_burn_in, T):\n",
        "  actions_ = episode_data['actions'][T_burn_in:T_burn_in+T]\n",
        "  actions = np.zeros((T), dtype=int)\n",
        "  actions[actions_ == 'w'] = 0\n",
        "  actions[actions_ == 'd'] = 1\n",
        "  actions[actions_ == 'a'] = 2\n",
        "\n",
        "  positions = episode_data['positions'][T_burn_in:T_burn_in+T]\n",
        "\n",
        "  rotations = episode_data['rotations'][T_burn_in:T_burn_in+T]\n",
        "  rotations = rotations[:,1]\n",
        "\n",
        "  images = episode_data['rgb_agent'][T_burn_in:T_burn_in+T]\n",
        "\n",
        "  return actions, positions, rotations, images\n",
        "\n",
        "\n",
        "def get_clone_poses(\n",
        "    chmma,\n",
        "    observations: np.ndarray,\n",
        "    actions: np.ndarray,\n",
        "    positions: np.ndarray,\n",
        "    rotations: np.ndarray,\n",
        "    position_decimals: int = 0,\n",
        "    ignore_clone0: bool = False,\n",
        "):\n",
        "\n",
        "  states = chmma.decode(observations, actions)[1]\n",
        "\n",
        "  # For each clone, find which position, rotation it occurs mostly at.\n",
        "  # We need to ensure that the positions are rounded to some precision\n",
        "  # corresponding to a grid.\n",
        "  decoded_clones = np.unique(states)\n",
        "  if ignore_clone0:\n",
        "    decoded_clones = decoded_clones[1:]\n",
        "  decoded_clone_poses = []\n",
        "\n",
        "  for clone in decoded_clones:\n",
        "    idx = np.where(states == clone)\n",
        "    c_positions = np.around(positions[idx], decimals=position_decimals)\n",
        "    c_rotations = np.around(rotations[idx], decimals=-1)  # within 5 degrees\n",
        "\n",
        "    counts = {}\n",
        "    for i, c_pos in enumerate(c_positions):\n",
        "      c_rot = c_rotations[i]\n",
        "      if (c_pos[0], c_pos[-1], c_rot) in counts:\n",
        "        counts[(c_pos[0], c_pos[-1], c_rot)] += 1\n",
        "      else:\n",
        "        counts[(c_pos[0], c_pos[-1], c_rot)] = 1\n",
        "\n",
        "    decoded_clone_poses.append(max(counts, key=counts.get))\n",
        "\n",
        "  decoded_clone_pos_rot = {}\n",
        "\n",
        "  for key, val in enumerate(decoded_clone_poses):\n",
        "    px, pz, rot = val\n",
        "\n",
        "    decoded_clone_pos_rot[key] = val\n",
        "\n",
        "\n",
        "  return decoded_clone_pos_rot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R0b_w1VxEA5"
      },
      "source": [
        "## Load data and inspect ground truth positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mNvzVJUwznJ"
      },
      "outputs": [],
      "source": [
"folder_name = 'path/to/your/data/space_is_a_seq/transitive_learning_exp/ramps7x7'"
        "\n",
        "episode_filenames = ['quad1111_s0_ws0_d5_50k.npz',\n",
        "                     'quad1111_s0_ws1_d5_50k.npz',\n",
        "                     'quad1111_s0_ws2_d5_50k.npz',\n",
        "                     'quad1111_s0_ws3_d5_50k.npz',\n",
        "                     'quad1111_s0_ws4_d5_50k.npz',\n",
        "                     'quad1111_s0_ws5_d5_50k.npz',\n",
        "                     'quad1111_s0_ws6_d5_50k.npz',\n",
        "                     'quad1111_s0_ws7_d5_50k.npz',\n",
        "                     ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6njhwiPgxHVV"
      },
      "outputs": [],
      "source": [
        "# parameters and init for clustering\n",
        "\n",
        "T_burn_in = 1_000 # burn in time\n",
        "T = 45_000\n",
        "\n",
        "g_images = []\n",
        "images_all = []\n",
        "actions_all = []\n",
        "positions_all = []\n",
        "positions_r_all = []\n",
        "rotations_all = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-3rnvVUxIk_"
      },
      "outputs": [],
      "source": [
        "g_locations = set()\n",
        "\n",
        "for episode_filename in episode_filenames:\n",
        "  print(f'Loading episode {episode_filename}')\n",
        "  episode_data = utils.load_arrays(folder_name + episode_filename)\n",
        "\n",
        "  # extract episode data\n",
        "  actions, positions, rotations, images = extract_data_from_episode(episode_data, T_burn_in, T)\n",
        "  images_all.append(images.copy())\n",
        "  actions_all.append(actions.copy())\n",
        "\n",
        "  positions = 4*(positions - 0.25)\n",
        "  positions_r = np.round(positions) # round positions\n",
        "  rotations = np.round(rotations) # round rotations\n",
        "\n",
        "  headings = np.unique(rotations)\n",
        "  positions_all.append(positions.copy())\n",
        "  positions_r_all.append(positions_r.copy())\n",
        "  rotations_all.append(rotations.copy())\n",
        "\n",
        "  # find unique locations in each episode\n",
        "\n",
        "  for i, (px, _, py) in enumerate(positions_r):\n",
        "    ph = rotations[i]\n",
        "    if (px, py, ph) not in g_locations:\n",
        "      g_locations.add((px, py, ph))\n",
        "      g_images.append(images[i])\n",
        "\n",
        "print(f'No. of locations on the grid = {len(g_locations)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kEE9xKfxLGR"
      },
      "outputs": [],
      "source": [
        "# visualize positions from all episodes\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
        "for k in range(len(images_all)):\n",
        "  ax.plot(positions_r_all[k][:,0], positions_r_all[k][:,2], '.')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZYQSs-_XTXv"
      },
      "source": [
        "## Online clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRpNatg0Xb5x"
      },
      "outputs": [],
      "source": [
        "quantizer = utils.OnlineClustering(threshold=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzTo-Uh5XfHH"
      },
      "outputs": [],
      "source": [
        "cluster_indices, centers = quantizer.cluster(np.concatenate(images_all, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffL0UY71esNG"
      },
      "outputs": [],
      "source": [
        "n_walks = len(images_all)\n",
        "walk_len = images_all[0].shape[0]\n",
        "n_walks, walk_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzJC968rgMmk"
      },
      "outputs": [],
      "source": [
        "x_all = [cluster_indices[k*walk_len:(k+1)*walk_len] for k in range(n_walks)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBhnTMWpYEUo"
      },
      "outputs": [],
      "source": [
        "# Example cluster center images\n",
        "\n",
        "fig, axs = plt.subplots(6,6, figsize=(14,14))\n",
        "\n",
        "idxs = np.random.choice(np.arange(centers.shape[0]), size=36, replace=False)\n",
        "idxs = np.sort(idxs)\n",
        "\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.imshow(centers[idxs[i]])\n",
        "  ax.set_title(f'cc = {idxs[i]}')\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieklAu1pyZEA"
      },
      "source": [
        "## Concatenate observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gsdguWtyWm6"
      },
      "outputs": [],
      "source": [
        "# split data into chunks of equal size\n",
        "\n",
        "N_splits = 4\n",
        "x_split = np.vstack([temp.reshape(N_splits,-1) for temp in x_all])\n",
        "a_split = np.vstack([temp.reshape(N_splits,-1) for temp in actions_all])\n",
        "positions_r_split = np.vstack([temp.reshape(N_splits,-1,3) for temp in positions_r_all])\n",
        "rotations_split = np.vstack([temp.reshape(N_splits,-1) for temp in rotations_all])\n",
        "x_split.shape, a_split.shape, positions_r_split.shape, rotations_split.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXpoL93Pyd4V"
      },
      "outputs": [],
      "source": [
        "# randomize the order of the chunks\n",
        "N_episodes = x_split.shape[0]\n",
        "order = np.random.permutation(N_episodes)\n",
        "x_split = x_split[order]\n",
        "a_split = a_split[order]\n",
        "positions_r_split = positions_r_split[order]\n",
        "rotations_split = rotations_split[order]\n",
        "x_split.shape, a_split.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddqRKUYmyeSw"
      },
      "outputs": [],
      "source": [
        "x_concatenated = np.array([0])\n",
        "a_concatenated = np.array([0])\n",
        "positions_r_concatenated = np.array([0,0,0])[None,:]\n",
        "rotations_concatenated = np.array([0])\n",
        "\n",
        "for k in range(N_episodes):\n",
        "  x_concatenated = np.concatenate((x_concatenated, x_split[k]+1, np.array([0])))\n",
        "  a_concatenated = np.concatenate((a_concatenated, a_split[k][0:-1] + 1, np.array([0, 0])))\n",
        "  positions_r_concatenated = np.vstack((positions_r_concatenated, positions_r_split[k], np.array([0,0,0])[None,:]))\n",
        "  rotations_concatenated = np.concatenate((rotations_concatenated, rotations_split[k], np.array([0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9BGeFBuyfg8"
      },
      "outputs": [],
      "source": [
        "print(f'Shape of x_concatenated: {x_concatenated.shape}, shape of a_concatenated: {a_concatenated.shape}')\n",
        "print(f'Shape of positions_r_concatenated: {positions_r_concatenated.shape}')\n",
        "print(f'Shape of rotations_concatenated: {rotations_concatenated.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlruxV4PyhAp"
      },
      "outputs": [],
      "source": [
        "len(np.unique(x_concatenated)), len(np.unique(a_concatenated))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNMppXlbylq_"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft9xIMFlyj5p"
      },
      "outputs": [],
      "source": [
        "#@title Clone allocation based on relative frequency of occurrence\n",
        "n_clones = (np.round(np.unique(cluster_indices, return_counts=True)[1]/40) + 1).astype(int)\n",
        "plt.plot(n_clones, 'b.-')\n",
        "plt.xlabel('Clone index')\n",
        "plt.ylabel('No. of clones')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2QBBuI7ynAk"
      },
      "outputs": [],
      "source": [
        "# add a single clone for the dummy observation\n",
        "n_clones = np.concatenate((np.array([1]), n_clones))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIzv-2hYyqi-"
      },
      "outputs": [],
      "source": [
        "n_actions = len(np.unique(a_concatenated))\n",
        "print(f'n_actions: {n_actions}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvi6B453yq1Z"
      },
      "outputs": [],
      "source": [
        "#@title Initialize model\n",
        "pseudocount = 5e-4\n",
        "kwargs = dict(n_clones=n_clones,\n",
        "          pseudocount=pseudocount,\n",
        "          n_actions=n_actions,\n",
        "          batched=True,\n",
        "          use_bfloat16=False)\n",
        "\n",
        "model = cscg_factory.build_cscg(implementation='he', seed=0, kwargs=kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-vgi3ikM4ZP"
      },
      "outputs": [],
      "source": [
        "#@title EM training\n",
        "convergence_em = model.learn_em_transition(observations=x_concatenated, actions=a_concatenated, n_iter=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtKHDLY6SWG4"
      },
      "outputs": [],
      "source": [
        "#@title Viterbi training\n",
        "convergence_vit = model.learn_viterbi_transition(observations=x_concatenated,\n",
        "                                                 actions=a_concatenated,\n",
        "                                                 n_iter=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnZABB-Nig7j"
      },
      "outputs": [],
      "source": [
        "#@title Decode states\n",
        "model.set_pseudocount(1e-6)\n",
        "\n",
        "states = model.decode(observations=x_concatenated, actions=a_concatenated)[1]\n",
        "print(f'No. of unique states = {len(np.unique(states))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjv6ETnegUCT"
      },
      "source": [
        "## Plotting the transition graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PREoYzByiipS"
      },
      "outputs": [],
      "source": [
        "#@title Create transition graph\n",
        "\n",
        "v = np.unique(states)[1:]\n",
        "C = model.counts_matrix[:, v][:, :, v]\n",
        "C = C[1:]\n",
        "C = C.sum(axis=0)\n",
        "C /= C.sum(1,keepdims=True)\n",
        "\n",
        "g = nx.from_numpy_array(C \u003e 0.15, create_using=nx.DiGraph)\n",
        "g.remove_edges_from(nx.selfloop_edges(g))\n",
        "\n",
        "cmap = matplotlib.cm.get_cmap('Spectral')\n",
        "x_max = np.max(x_concatenated)\n",
        "\n",
        "node_labels = np.arange(x_max+1).repeat(n_clones)[v]\n",
        "colors = [cmap(nl)[:3] for nl in node_labels / node_labels.max()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSrkNIbuinUs"
      },
      "outputs": [],
      "source": [
        "#@title Assign clone positions\n",
        "pos_gt = get_clone_poses(model,\n",
        "                         observations=x_concatenated,\n",
        "                         actions=a_concatenated,\n",
        "                         positions=positions_r_concatenated,\n",
        "                         rotations=rotations_concatenated,\n",
        "                         position_decimals=0,\n",
        "                         ignore_clone0=True)\n",
        "\n",
        "pos_gt_2D = {}\n",
        "d = 0.5\n",
        "for clone in pos_gt:\n",
        "  cx, cy, ch = pos_gt[clone]\n",
        "  if ch == 0.0:\n",
        "    pos_gt_2D[clone] = (cx+d, cy)\n",
        "  elif ch == 90.0:\n",
        "    pos_gt_2D[clone] = (cx, cy+d)\n",
        "  elif ch == 180.0:\n",
        "    pos_gt_2D[clone] = (cx-d, cy)\n",
        "  elif ch == 270.0:\n",
        "    pos_gt_2D[clone] = (cx, cy-d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np84UNO6io5k"
      },
      "outputs": [],
      "source": [
        "#@title Plot graph with clones assigned positions using gt information\n",
        "pos = pos_gt_2D\n",
        "ns = 50\n",
        "fig, ax = plt.subplots(1,1, figsize=(15, 15))\n",
        "nx.draw_networkx(g, pos=pos, ax=ax, with_labels=False, node_size=ns, alpha=0.1)\n",
        "nx.draw_networkx_nodes(g, pos=pos, ax=ax, node_size=ns, node_color=colors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prWlMRThpC3n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {},
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
